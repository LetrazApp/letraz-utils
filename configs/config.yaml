server:
  port: 8080
  host: "0.0.0.0"
  read_timeout: "30s"
  write_timeout: "30s"
  idle_timeout: "60s"

workers:
  pool_size: 10
  queue_size: 100
  rate_limit: 60  # requests per minute
  timeout: "30s"
  max_retries: 3

llm:
  provider: "openai"
  api_key: ""  # Set via environment variable LLM_API_KEY
  model: "gpt-3.5-turbo"
  max_tokens: 4096
  temperature: 0.1
  timeout: "30s"

scraper:
  user_agent: "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
  proxies: []
  max_retries: 3
  request_timeout: "30s"
  headless_mode: true
  stealth_mode: true

logging:
  level: "warn"  # Reduced from "info" to "warn" for production use
  format: "json"
  output: "stdout" 